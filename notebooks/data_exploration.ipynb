{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d78f89a",
   "metadata": {},
   "source": [
    "# VisDrone Dataset Exploration\n",
    "\n",
    "This notebook explores the VisDrone dataset to understand its structure, characteristics, and suitability for autonomous drone detection tasks.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Dataset Overview](#dataset-overview)\n",
    "2. [Data Loading and Structure](#data-loading)\n",
    "3. [Class Distribution Analysis](#class-distribution)\n",
    "4. [Image Characteristics](#image-characteristics)\n",
    "5. [Annotation Analysis](#annotation-analysis)\n",
    "6. [Challenges and Opportunities](#challenges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ae5bf09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment setup complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "import json\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Configuration\n",
    "DATASET_DIR = Path('../data/visdrone')\n",
    "FIGURES_DIR = Path('../results/figures')\n",
    "FIGURES_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d84216",
   "metadata": {},
   "source": [
    "## Dataset Overview {#dataset-overview}\n",
    "\n",
    "The VisDrone dataset is a large-scale benchmark dataset for object detection and tracking in drone-captured images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94b7f7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Structure:\n",
      "  train: Not found\n",
      "  val: Not found\n",
      "  test: Not found\n"
     ]
    }
   ],
   "source": [
    "# VisDrone class definitions\n",
    "VISDRONE_CLASSES = {\n",
    "    0: 'ignored',\n",
    "    1: 'pedestrian',\n",
    "    2: 'people',\n",
    "    3: 'bicycle',\n",
    "    4: 'car',\n",
    "    5: 'van',\n",
    "    6: 'truck',\n",
    "    7: 'tricycle',\n",
    "    8: 'awning-tricycle',\n",
    "    9: 'bus',\n",
    "    10: 'motor'\n",
    "}\n",
    "\n",
    "# Check dataset structure\n",
    "def explore_dataset_structure(dataset_dir):\n",
    "    \"\"\"Explore the structure of the VisDrone dataset.\"\"\"\n",
    "    structure = {}\n",
    "    \n",
    "    for split in ['train', 'val', 'test']:\n",
    "        split_dir = dataset_dir / split\n",
    "        if split_dir.exists():\n",
    "            images_dir = split_dir / 'images'\n",
    "            annotations_dir = split_dir / 'annotations'\n",
    "            \n",
    "            structure[split] = {\n",
    "                'exists': True,\n",
    "                'images': len(list(images_dir.glob('*.jpg'))) if images_dir.exists() else 0,\n",
    "                'annotations': len(list(annotations_dir.glob('*.txt'))) if annotations_dir.exists() else 0\n",
    "            }\n",
    "        else:\n",
    "            structure[split] = {'exists': False}\n",
    "    \n",
    "    return structure\n",
    "\n",
    "dataset_structure = explore_dataset_structure(DATASET_DIR)\n",
    "print(\"Dataset Structure:\")\n",
    "for split, info in dataset_structure.items():\n",
    "    if info['exists']:\n",
    "        print(f\"  {split}: {info['images']} images, {info['annotations']} annotations\")\n",
    "    else:\n",
    "        print(f\"  {split}: Not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eabe4bb",
   "metadata": {},
   "source": [
    "## Data Loading and Structure {#data-loading}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc0a334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_visdrone_annotations(annotation_file):\n",
    "    \"\"\"Load VisDrone annotations from a text file.\"\"\"\n",
    "    annotations = []\n",
    "    \n",
    "    if not annotation_file.exists():\n",
    "        return annotations\n",
    "    \n",
    "    with open(annotation_file, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            parts = line.split(',')\n",
    "            if len(parts) != 8:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                annotation = {\n",
    "                    'bbox_left': int(parts[0]),\n",
    "                    'bbox_top': int(parts[1]),\n",
    "                    'bbox_width': int(parts[2]),\n",
    "                    'bbox_height': int(parts[3]),\n",
    "                    'score': int(parts[4]),\n",
    "                    'object_category': int(parts[5]),\n",
    "                    'truncation': int(parts[6]),\n",
    "                    'occlusion': int(parts[7])\n",
    "                }\n",
    "                annotations.append(annotation)\n",
    "            except ValueError:\n",
    "                continue\n",
    "    \n",
    "    return annotations\n",
    "\n",
    "def analyze_split(dataset_dir, split_name, max_files=None):\n",
    "    \"\"\"Analyze a dataset split.\"\"\"\n",
    "    split_dir = dataset_dir / split_name\n",
    "    if not split_dir.exists():\n",
    "        return None\n",
    "    \n",
    "    images_dir = split_dir / 'images'\n",
    "    annotations_dir = split_dir / 'annotations'\n",
    "    \n",
    "    image_files = list(images_dir.glob('*.jpg'))\n",
    "    if max_files:\n",
    "        image_files = image_files[:max_files]\n",
    "    \n",
    "    analysis = {\n",
    "        'split': split_name,\n",
    "        'total_images': len(image_files),\n",
    "        'image_sizes': [],\n",
    "        'annotations_per_image': [],\n",
    "        'class_distribution': Counter(),\n",
    "        'bbox_areas': [],\n",
    "        'truncation_stats': Counter(),\n",
    "        'occlusion_stats': Counter()\n",
    "    }\n",
    "    \n",
    "    for img_file in image_files:\n",
    "        # Load image to get dimensions\n",
    "        img = cv2.imread(str(img_file))\n",
    "        if img is not None:\n",
    "            h, w = img.shape[:2]\n",
    "            analysis['image_sizes'].append((w, h))\n",
    "        \n",
    "        # Load corresponding annotation\n",
    "        ann_file = annotations_dir / (img_file.stem + '.txt')\n",
    "        annotations = load_visdrone_annotations(ann_file)\n",
    "        \n",
    "        analysis['annotations_per_image'].append(len(annotations))\n",
    "        \n",
    "        for ann in annotations:\n",
    "            analysis['class_distribution'][ann['object_category']] += 1\n",
    "            analysis['bbox_areas'].append(ann['bbox_width'] * ann['bbox_height'])\n",
    "            analysis['truncation_stats'][ann['truncation']] += 1\n",
    "            analysis['occlusion_stats'][ann['occlusion']] += 1\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "# Analyze train split (sample for speed)\n",
    "print(\"Analyzing dataset splits...\")\n",
    "train_analysis = analyze_split(DATASET_DIR, 'train', max_files=1000)\n",
    "val_analysis = analyze_split(DATASET_DIR, 'val')\n",
    "\n",
    "print(f\"Train analysis: {train_analysis['total_images'] if train_analysis else 0} images processed\")\n",
    "print(f\"Validation analysis: {val_analysis['total_images'] if val_analysis else 0} images processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f56c5e",
   "metadata": {},
   "source": [
    "## Class Distribution Analysis {#class-distribution}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68f5ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_distribution(analysis_results, save_path=None):\n",
    "    \"\"\"Plot class distribution across dataset splits.\"\"\"\n",
    "    fig, axes = plt.subplots(1, len(analysis_results), figsize=(15, 6))\n",
    "    if len(analysis_results) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, (split_name, analysis) in enumerate(analysis_results.items()):\n",
    "        if analysis is None:\n",
    "            continue\n",
    "            \n",
    "        # Prepare data\n",
    "        classes = []\n",
    "        counts = []\n",
    "        \n",
    "        for class_id in sorted(analysis['class_distribution'].keys()):\n",
    "            if class_id in VISDRONE_CLASSES:\n",
    "                classes.append(VISDRONE_CLASSES[class_id])\n",
    "                counts.append(analysis['class_distribution'][class_id])\n",
    "        \n",
    "        # Create bar plot\n",
    "        ax = axes[i]\n",
    "        bars = ax.bar(range(len(classes)), counts)\n",
    "        ax.set_title(f'{split_name.title()} Split Class Distribution')\n",
    "        ax.set_xlabel('Object Class')\n",
    "        ax.set_ylabel('Number of Instances')\n",
    "        ax.set_xticks(range(len(classes)))\n",
    "        ax.set_xticklabels(classes, rotation=45, ha='right')\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, count in zip(bars, counts):\n",
    "            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(counts)*0.01,\n",
    "                   str(count), ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Plot class distributions\n",
    "analysis_dict = {}\n",
    "if train_analysis:\n",
    "    analysis_dict['train'] = train_analysis\n",
    "if val_analysis:\n",
    "    analysis_dict['val'] = val_analysis\n",
    "\n",
    "if analysis_dict:\n",
    "    plot_class_distribution(analysis_dict, FIGURES_DIR / 'class_distribution.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500e01df",
   "metadata": {},
   "source": [
    "## Image Characteristics {#image-characteristics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4664ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_characteristics(analysis_results, save_path=None):\n",
    "    \"\"\"Plot image size distribution and other characteristics.\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    for split_name, analysis in analysis_results.items():\n",
    "        if analysis is None:\n",
    "            continue\n",
    "        \n",
    "        # Image sizes\n",
    "        widths = [size[0] for size in analysis['image_sizes']]\n",
    "        heights = [size[1] for size in analysis['image_sizes']]\n",
    "        \n",
    "        # Plot 1: Image width distribution\n",
    "        axes[0, 0].hist(widths, bins=30, alpha=0.7, label=split_name)\n",
    "        axes[0, 0].set_title('Image Width Distribution')\n",
    "        axes[0, 0].set_xlabel('Width (pixels)')\n",
    "        axes[0, 0].set_ylabel('Frequency')\n",
    "        axes[0, 0].legend()\n",
    "        \n",
    "        # Plot 2: Image height distribution\n",
    "        axes[0, 1].hist(heights, bins=30, alpha=0.7, label=split_name)\n",
    "        axes[0, 1].set_title('Image Height Distribution')\n",
    "        axes[0, 1].set_xlabel('Height (pixels)')\n",
    "        axes[0, 1].set_ylabel('Frequency')\n",
    "        axes[0, 1].legend()\n",
    "        \n",
    "        # Plot 3: Annotations per image\n",
    "        axes[1, 0].hist(analysis['annotations_per_image'], bins=30, alpha=0.7, label=split_name)\n",
    "        axes[1, 0].set_title('Annotations per Image')\n",
    "        axes[1, 0].set_xlabel('Number of Annotations')\n",
    "        axes[1, 0].set_ylabel('Frequency')\n",
    "        axes[1, 0].legend()\n",
    "        \n",
    "        # Plot 4: Bounding box areas\n",
    "        log_areas = np.log10(np.array(analysis['bbox_areas']) + 1)\n",
    "        axes[1, 1].hist(log_areas, bins=30, alpha=0.7, label=split_name)\n",
    "        axes[1, 1].set_title('Bounding Box Areas (log scale)')\n",
    "        axes[1, 1].set_xlabel('Log10(Area + 1)')\n",
    "        axes[1, 1].set_ylabel('Frequency')\n",
    "        axes[1, 1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "if analysis_dict:\n",
    "    plot_image_characteristics(analysis_dict, FIGURES_DIR / 'image_characteristics.png')\n",
    "    \n",
    "    # Print statistics\n",
    "    for split_name, analysis in analysis_dict.items():\n",
    "        if analysis:\n",
    "            print(f\"\\n{split_name.title()} Split Statistics:\")\n",
    "            print(f\"  Total images: {analysis['total_images']}\")\n",
    "            print(f\"  Total annotations: {sum(analysis['class_distribution'].values())}\")\n",
    "            print(f\"  Avg annotations per image: {np.mean(analysis['annotations_per_image']):.1f}\")\n",
    "            print(f\"  Avg bbox area: {np.mean(analysis['bbox_areas']):.1f} pixels²\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6841bc",
   "metadata": {},
   "source": [
    "## Annotation Analysis {#annotation-analysis}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8566885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_annotation_quality(analysis_results):\n",
    "    \"\"\"Analyze annotation quality metrics.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    for split_name, analysis in analysis_results.items():\n",
    "        if analysis is None:\n",
    "            continue\n",
    "        \n",
    "        # Truncation statistics\n",
    "        truncation_labels = ['No truncation', 'Partial truncation', 'Heavy truncation']\n",
    "        truncation_counts = [analysis['truncation_stats'].get(i, 0) for i in range(3)]\n",
    "        \n",
    "        axes[0].bar(truncation_labels, truncation_counts, alpha=0.7, label=split_name)\n",
    "        axes[0].set_title('Truncation Statistics')\n",
    "        axes[0].set_ylabel('Number of Objects')\n",
    "        axes[0].legend()\n",
    "        \n",
    "        # Occlusion statistics\n",
    "        occlusion_labels = ['No occlusion', 'Partial occlusion', 'Heavy occlusion']\n",
    "        occlusion_counts = [analysis['occlusion_stats'].get(i, 0) for i in range(3)]\n",
    "        \n",
    "        axes[1].bar(occlusion_labels, occlusion_counts, alpha=0.7, label=split_name)\n",
    "        axes[1].set_title('Occlusion Statistics')\n",
    "        axes[1].set_ylabel('Number of Objects')\n",
    "        axes[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIGURES_DIR / 'annotation_quality.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "if analysis_dict:\n",
    "    analyze_annotation_quality(analysis_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebb44d9",
   "metadata": {},
   "source": [
    "## Sample Images Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7376050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sample_images(dataset_dir, split='train', num_samples=4):\n",
    "    \"\"\"Visualize sample images with annotations.\"\"\"\n",
    "    split_dir = dataset_dir / split\n",
    "    if not split_dir.exists():\n",
    "        print(f\"Split {split} not found\")\n",
    "        return\n",
    "    \n",
    "    images_dir = split_dir / 'images'\n",
    "    annotations_dir = split_dir / 'annotations'\n",
    "    \n",
    "    image_files = list(images_dir.glob('*.jpg'))[:num_samples]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(VISDRONE_CLASSES)))\n",
    "    \n",
    "    for i, img_file in enumerate(image_files):\n",
    "        # Load image\n",
    "        img = cv2.imread(str(img_file))\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Load annotations\n",
    "        ann_file = annotations_dir / (img_file.stem + '.txt')\n",
    "        annotations = load_visdrone_annotations(ann_file)\n",
    "        \n",
    "        # Draw annotations\n",
    "        for ann in annotations:\n",
    "            if ann['object_category'] == 0:  # Skip ignored regions\n",
    "                continue\n",
    "            \n",
    "            x1 = ann['bbox_left']\n",
    "            y1 = ann['bbox_top']\n",
    "            x2 = x1 + ann['bbox_width']\n",
    "            y2 = y1 + ann['bbox_height']\n",
    "            \n",
    "            color = colors[ann['object_category'] % len(colors)][:3]\n",
    "            color = tuple(int(c * 255) for c in color)\n",
    "            \n",
    "            cv2.rectangle(img_rgb, (x1, y1), (x2, y2), color, 2)\n",
    "            \n",
    "            # Add class label\n",
    "            class_name = VISDRONE_CLASSES.get(ann['object_category'], 'unknown')\n",
    "            cv2.putText(img_rgb, class_name, (x1, y1-5), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "        \n",
    "        # Display\n",
    "        axes[i].imshow(img_rgb)\n",
    "        axes[i].set_title(f'{img_file.name}\\n{len(annotations)} objects')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIGURES_DIR / f'sample_images_{split}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize sample images\n",
    "if train_analysis:\n",
    "    visualize_sample_images(DATASET_DIR, 'train')\n",
    "elif val_analysis:\n",
    "    visualize_sample_images(DATASET_DIR, 'val')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8c08bf",
   "metadata": {},
   "source": [
    "## Challenges and Opportunities {#challenges}\n",
    "\n",
    "Based on the dataset analysis, we can identify several key challenges and opportunities for autonomous drone detection:\n",
    "\n",
    "### Challenges\n",
    "1. **Small Objects**: Many objects in drone imagery are small, requiring specialized detection techniques\n",
    "2. **Class Imbalance**: Some classes have significantly more instances than others\n",
    "3. **Occlusion and Truncation**: Real-world conditions create challenging detection scenarios\n",
    "4. **Scale Variation**: Objects appear at various scales due to altitude differences\n",
    "\n",
    "### Opportunities\n",
    "1. **Topological Filtering**: Betti numbers can help identify legitimate object groupings vs. false positives\n",
    "2. **Contextual Reasoning**: Spatial relationships between objects can improve detection\n",
    "3. **Multi-scale Training**: The dataset provides good coverage of different scales\n",
    "4. **Real-world Applicability**: The dataset represents realistic drone deployment scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415a6301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save analysis summary\n",
    "summary = {\n",
    "    'dataset_overview': {\n",
    "        'classes': VISDRONE_CLASSES,\n",
    "        'splits_analyzed': list(analysis_dict.keys())\n",
    "    },\n",
    "    'analysis_results': {}\n",
    "}\n",
    "\n",
    "for split_name, analysis in analysis_dict.items():\n",
    "    if analysis:\n",
    "        summary['analysis_results'][split_name] = {\n",
    "            'total_images': analysis['total_images'],\n",
    "            'total_annotations': sum(analysis['class_distribution'].values()),\n",
    "            'avg_annotations_per_image': float(np.mean(analysis['annotations_per_image'])),\n",
    "            'class_distribution': dict(analysis['class_distribution']),\n",
    "            'avg_bbox_area': float(np.mean(analysis['bbox_areas'])) if analysis['bbox_areas'] else 0\n",
    "        }\n",
    "\n",
    "# Save to file\n",
    "with open(FIGURES_DIR / 'dataset_analysis_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"Dataset exploration completed!\")\n",
    "print(f\"Results saved to: {FIGURES_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
